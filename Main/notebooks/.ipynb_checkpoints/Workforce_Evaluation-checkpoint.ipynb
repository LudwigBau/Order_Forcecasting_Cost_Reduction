{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87cf9641-c901-40a0-92df-ae8f6d6e163d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import standard libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "# Import statistical libraries\n",
    "from scipy import stats\n",
    "from scipy.stats import median_test, mannwhitneyu, pearsonr\n",
    "from scipy.optimize import curve_fit, minimize_scalar\n",
    "from scipy.integrate import quad\n",
    "\n",
    "# Import machine learning libraries\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Import optimization libraries\n",
    "import gurobipy as gp\n",
    "from gurobipy import GRB\n",
    "\n",
    "# Import visualization libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Import custom utilities\n",
    "sys.path.append('/Users/ludwigbaunach/Documents/Studium/PhD/Alaiko/Paper_1_Project/Main/src')\n",
    "from utils.simulation_utils import simulation_main, create_weeks\n",
    "\n",
    "# Configure warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "826a84b3-325a-4cda-ac40-a0f7305f6b88",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edac3750-0cd1-4c2b-86b8-1575a61d22bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sturucture: [\"model\"][\"variable\"][\"array (7,6,400)\"]\n",
    "single_dict = pd.read_pickle(\"../data/modelling_results/workforce_results_single_all_dict231027.pickle\")\n",
    "c_robust_dict = pd.read_pickle(\"../data/modelling_results/workforce_results_robust_cost_dict231027.pickle\")\n",
    "p_robust_dict = pd.read_pickle(\"../data/modelling_results/workforce_results_robust_psi_dict231027.pickle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f480f9-c70a-497a-a480-e1fe177e1847",
   "metadata": {},
   "source": [
    "## Create Total Evaluation DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7cc03bc-5ab0-49d3-8c0b-f3141b6c8ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty DataFrame to store the evaluation metrics\n",
    "evaluation_df = pd.DataFrame()\n",
    "\n",
    "# Benchmark and Perfect Forecast Models\n",
    "benchmark_model = 'L_4_sarimax'\n",
    "perfect_model = 'actual'\n",
    "\n",
    "# Variables\n",
    "variables = ['cost', 'w_p', 'w_e', 'y_o', 'z', 'v']\n",
    "variables_name = ['cost', 'planned_workers', 'extra_workers', 'overtime', 'backlog', 'overcapacity']\n",
    "\n",
    "# Loop through each model to evaluate\n",
    "for model, variable_dict in single_dict.items():\n",
    "    \n",
    "    # Initialize a dictionary to hold evaluation metrics for this model\n",
    "    data_dict = {\n",
    "        'model': model,\n",
    "        'week': 4,\n",
    "        'psi_scenario': 0.8,\n",
    "        'cost_scenario': 1,\n",
    "    }\n",
    "    \n",
    "    for variable, name in zip(variables, variables_name):\n",
    "        \n",
    "        # Extract and flatten data\n",
    "        model_data = np.sum(single_dict[model][variable], axis=1).flatten()\n",
    "        bench_data = np.sum(single_dict[benchmark_model][variable], axis=1).flatten()\n",
    "        perf_data = np.sum(single_dict[perfect_model][variable], axis=1).flatten()\n",
    "        \n",
    "        # Calculate mean, median, and sum values\n",
    "        mean_value = np.mean(model_data)\n",
    "        median_value = np.median(model_data)\n",
    "        sum_value = np.sum(model_data)\n",
    "        \n",
    "        # Calculate relative performance to benchmark and perfect forecast\n",
    "        rel_total_bench = np.round(((sum_value - np.sum(bench_data)) / np.sum(bench_data)) * 100, 2)\n",
    "        rel_total_perf = np.round(((sum_value - np.sum(perf_data)) / np.sum(perf_data)) * 100, 2)\n",
    "        \n",
    "        # Calculate p-value using mann whitney u test\n",
    "        _, p_value_bench = mannwhitneyu(model_data, bench_data, alternative='two-sided')\n",
    "        _, p_value_perf, = mannwhitneyu(model_data, perf_data, alternative='two-sided')\n",
    "        \n",
    "        # Calculate p-values using t-test for 'cost' variable\n",
    "        if variable == 'cost':\n",
    "            _, p_value_mean_bench = mannwhitneyu(model_data, bench_data, alternative='two-sided')\n",
    "            _, p_value_mean_perf = mannwhitneyu(model_data, perf_data, alternative='two-sided')\n",
    "            \n",
    "            # Calculate mean daily savings relative to benchmark and perfect forecast\n",
    "            mean_savings_bench = np.round(np.mean(((model_data - bench_data) / bench_data) * 100),2)\n",
    "            mean_savings_perf = np.round(np.mean(((model_data - perf_data) / perf_data) * 100),2)\n",
    "            \n",
    "            data_dict.update({\n",
    "                'mean_savings_bench': mean_savings_bench,\n",
    "                'mean_savings_perf': mean_savings_perf,\n",
    "                f'p_value_mean_bench_{name}': p_value_mean_bench,\n",
    "                f'p_value_mean_perf_{name}': p_value_mean_perf\n",
    "            })\n",
    "        \n",
    "        # Update data_dict\n",
    "        data_dict.update({\n",
    "            f'mean_{name}': mean_value,\n",
    "            f'median_{name}': median_value,\n",
    "            f'rel_total_bench_{name}': rel_total_bench,\n",
    "            f'rel_total_perf_{name}': rel_total_perf,\n",
    "            f'p_value_bench_{name}': p_value_bench,\n",
    "            f'p_value_perf_{name}': p_value_perf\n",
    "        })\n",
    "        \n",
    "    # Convert data_dict to DataFrame and append to evaluation_df\n",
    "    temp_df = pd.DataFrame([data_dict])\n",
    "    evaluation_df = pd.concat([evaluation_df, temp_df], ignore_index=True)\n",
    "\n",
    "# Sort DataFrame by relative performance to benchmark for 'cost'\n",
    "evaluation_df.sort_values(\"mean_savings_bench\", inplace=True)\n",
    "\n",
    "# Display the evaluation DataFrame\n",
    "evaluation_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d81453-78a5-440b-9410-a6122352559a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to add asterisks based on p-value\n",
    "def add_asterisks(value, p_value):\n",
    "    if p_value <= 0.001:\n",
    "        return f\"{value}***\"\n",
    "    elif p_value <= 0.01:\n",
    "        return f\"{value}**\"\n",
    "    elif p_value <= 0.05:\n",
    "        return f\"{value}*\"\n",
    "    else:\n",
    "        return f\"{value}\"\n",
    "\n",
    "# Initialize an empty DataFrame to store the custom table\n",
    "custom_table_df = pd.DataFrame()\n",
    "\n",
    "# Iterate through each row in the evaluation DataFrame\n",
    "for index, row in evaluation_df.iterrows():\n",
    "    custom_dict = {\n",
    "        'model': row['model'],\n",
    "        'week': row['week'],\n",
    "        'psi_scenario': row['psi_scenario'],\n",
    "        'cost_scenario': row['cost_scenario'],\n",
    "    }\n",
    "    \n",
    "    for variable, name in zip(variables, variables_name):\n",
    "        \n",
    "        # Averages\n",
    "        if variable == \"cost\":\n",
    "            mean_daily_savings_bench = row[f'mean_savings_bench']\n",
    "            mean_daily_savings_perf = row[f'mean_savings_perf']\n",
    "            p_value_mean_bench = row[f'p_value_mean_bench_{name}']\n",
    "            p_value_mean_perf = row[f'p_value_mean_perf_{name}']\n",
    "            \n",
    "            # Add asterisks to the relative performance measures based on p-value\n",
    "            rel_per_bench_str = add_asterisks(mean_daily_savings_bench, p_value_mean_bench)\n",
    "            rel_per_perf_str = add_asterisks(mean_daily_savings_perf, p_value_mean_perf)\n",
    "        \n",
    "            # Update custom_dict\n",
    "            custom_dict.update({\n",
    "                f'rel_bench_mean_{name}': rel_per_bench_str,\n",
    "                f'rel_perf_mean_{name}': rel_per_perf_str,\n",
    "            })\n",
    "        \n",
    "        # Total\n",
    "        rel_per_bench = row[f'rel_total_bench_{name}']\n",
    "        rel_per_perf = row[f'rel_total_perf_{name}']\n",
    "        p_value_bench = row[f'p_value_bench_{name}']\n",
    "        p_value_perf = row[f'p_value_perf_{name}']\n",
    "        \n",
    "        # Add asterisks to the relative performance measures based on p-value\n",
    "        rel_per_bench_str = add_asterisks(rel_per_bench, p_value_bench)\n",
    "        rel_per_perf_str = add_asterisks(rel_per_perf, p_value_perf)\n",
    "        \n",
    "        # Update custom_dict\n",
    "        custom_dict.update({\n",
    "            f'rel_bench_total_{name}': rel_per_bench_str,\n",
    "            f'rel_perf_total_{name}': rel_per_perf_str,\n",
    "        })\n",
    "        \n",
    "    # Create a DataFrame with the custom data\n",
    "    temp_df = pd.DataFrame(custom_dict, index=[0])\n",
    "    \n",
    "    # Concatenate the new DataFrame to the existing one\n",
    "    custom_table_df = pd.concat([custom_table_df, temp_df], ignore_index=True)\n",
    "\n",
    "# Save DF to Excel\n",
    "custom_table_df.to_excel(\"../data/modelling_results/workforce_eval_single_total.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e390c85-4e27-4169-a951-561c37537374",
   "metadata": {},
   "source": [
    "## Create Week Evaluation DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "315585a2-dab4-41a5-9007-a334274c621e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_weekly_robust_savings(robust_dict):\n",
    "    \n",
    "    # Set-Up\n",
    "    \n",
    "    # Variables \n",
    "    variables = ['cost', 'w_p', 'w_e', 'y_o', 'z', 'v']\n",
    "    variables_name = ['cost', 'planned_workers', 'extra_workers', 'overtime', 'backlog', 'overcapacity']\n",
    "\n",
    "    # Initialize an empty DataFrame to store the evaluation metrics\n",
    "    weekly_evaluation_df = pd.DataFrame()\n",
    "    \n",
    "    # Benchmark\n",
    "    benchmark_model = 'L_4_sarimax'\n",
    "\n",
    "    # Perfect Forecast\n",
    "    perfect_model = 'actual'\n",
    "    \n",
    "    # Loop through scenarios\n",
    "    for scenario in robust_dict.keys():\n",
    "        # Loop through models\n",
    "        for model, variable_dict in robust_dict[scenario].items():\n",
    "            # Loop through weeks (first value of arrays shape) \n",
    "            for week in range(c_robust_dict[scenario][model][variables[0]].shape[0]):\n",
    "                data_dict = {\n",
    "                    'model': model,\n",
    "                    'week': week+1,\n",
    "                    'scenario': scenario,\n",
    "                }\n",
    "\n",
    "                for variable, name in zip(variables, variables_name):\n",
    "                    \n",
    "                    # Extract weekly aggregated data\n",
    "                    weekly_model_data = np.sum(robust_dict[scenario][model][variable][week, :, :], axis=0)\n",
    "                    weekly_bench_data = np.sum(robust_dict[scenario][benchmark_model][variable][week, :, :], axis=0)\n",
    "                    weekly_perf_data = np.sum(robust_dict[scenario][perfect_model][variable][week, :, :], axis=0)\n",
    "                    \n",
    "                    # Extract total weekly data \n",
    "                    total_model_data = np.sum(robust_dict[scenario][model][variable][:, :, :], axis=1).flatten()\n",
    "                    total_bench_data = np.sum(robust_dict[scenario][benchmark_model][variable][:, :, :], axis=1).flatten()\n",
    "                    \n",
    "                    # extract sum per week \n",
    "                    sum_value = np.sum(weekly_model_data)\n",
    "                    sum_bench_value = np.sum(weekly_bench_data)\n",
    "                    sum_perf_value = np.sum(weekly_perf_data)\n",
    "                    \n",
    "                    # extract total sum (indicated by _t_)\n",
    "                    sum_t_value = np.sum(total_model_data)\n",
    "                    sum_t_bench_value = np.sum(total_bench_data)\n",
    "                    \n",
    "                    # Calculate average and standard deviation of model (weekly)\n",
    "                    median_value = np.round(np.median(weekly_model_data), 2)\n",
    "                    \n",
    "                    # Calculate average and standard deviation of benchmark and perfect forecast (weekly)\n",
    "                    median_bench = np.round(np.median(weekly_bench_data), 2)\n",
    "                    median_perf = np.round(np.median(weekly_perf_data), 2)\n",
    "\n",
    "                    # Calculate weekly sum savings and round two 2 \n",
    "                    rel_bench_values = np.round(((sum_value - sum_bench_value) / sum_bench_value) * 100, 2)\n",
    "                    rel_perf_values = np.round(((sum_value - sum_perf_value) / sum_perf_value) * 100, 2)\n",
    "                    \n",
    "                    # Calculate total sum savings \n",
    "                    rel_t_bench_values = np.round(((sum_t_value - sum_t_bench_value) / sum_t_bench_value) * 100, 2)\n",
    "\n",
    "                    # Calculate relative measures std\n",
    "                    rel_bench_avg = np.round(np.mean(((weekly_model_data - weekly_bench_data) / weekly_bench_data) * 100), 2)\n",
    "                    rel_perf_avg = np.round(np.mean(((weekly_model_data - weekly_perf_data) / weekly_perf_data) * 100), 2)\n",
    "                    rel_bench_std = np.round(np.std(((weekly_model_data - weekly_bench_data) / weekly_bench_data) * 100), 2)\n",
    "                    rel_perf_std = np.round(np.std(((weekly_model_data - weekly_perf_data) / weekly_perf_data) * 100), 2)\n",
    "                 \n",
    "                    # Calculate total mean and std\n",
    "                    rel_t_avg = np.round(np.mean((total_model_data - total_bench_data) / total_bench_data) * 100, 2)\n",
    "                    rel_t_std = np.round(np.std((total_model_data - total_bench_data) / total_bench_data) * 100, 2)\n",
    "                    \n",
    "                    # Calculate bench relative measures p-values (weekly)\n",
    "                    _, p_value_bench = mannwhitneyu(weekly_model_data, weekly_bench_data, alternative='two-sided')\n",
    "                    # Calculate perf relative measures p-values (weekly)\n",
    "                    _, p_value_perf = mannwhitneyu(weekly_model_data, weekly_perf_data, alternative='two-sided')\n",
    "                    # Calculate bench relative measures p-values (total)\n",
    "                    _, p_t_value_bench = mannwhitneyu(total_model_data, total_bench_data, alternative='two-sided')\n",
    "                    \n",
    "                    # Add asterisks\n",
    "                    rel_bench_ast = add_asterisks(rel_bench_values, p_value_bench)\n",
    "                    rel_bench_ast_avg = add_asterisks(rel_bench_avg, p_value_bench)\n",
    "                    \n",
    "                    rel_perf_ast = add_asterisks(rel_perf_values, p_value_perf)\n",
    "                    rel_perf_ast_avg = add_asterisks(rel_perf_avg, p_value_perf)\n",
    "                    \n",
    "                    rel_t_bench_ast = add_asterisks(rel_t_bench_values, p_t_value_bench)\n",
    "                    rel_t_bench_ast_avg = add_asterisks(rel_t_avg, p_t_value_bench)\n",
    "\n",
    "                    # Update data_dict\n",
    "                    data_dict.update({\n",
    "                        f'sum_{name}': sum_value,\n",
    "                        f'median_{name}': median_value,\n",
    "                        f'rel_bench_{name}': rel_bench_ast,\n",
    "                        f'rel_bench_avg_{name}': rel_bench_ast_avg,\n",
    "                        f'rel_bench_std_{name}': f'({rel_bench_std})',\n",
    "                        f'p_bench_{name}': p_value_bench,\n",
    "                        f'rel_perf_avg_{name}': rel_perf_ast_avg,\n",
    "                        f'rel_t_bench_{name}': rel_t_bench_ast,\n",
    "                        f'rel_t_bench_avg_{name}': rel_t_bench_ast_avg,\n",
    "                        f'rel_t_bench_std_{name}': f'({rel_t_std})',\n",
    "                    })\n",
    "\n",
    "                # Create a DataFrame with the custom data\n",
    "                temp_df = pd.DataFrame(data_dict, index=[0])\n",
    "\n",
    "                # Concatenate the new DataFrame to the existing one\n",
    "                weekly_evaluation_df = pd.concat([weekly_evaluation_df, temp_df], ignore_index=True)\n",
    "                \n",
    "    return weekly_evaluation_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ce2765-2947-430a-aedc-a14bdd11bc3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scenario_pivot(df, model, path_name=\"test_scenario_table\"):\n",
    "    # Filter the DataFrame to include only a specific model\n",
    "    filtered_df = df[df['model'] == model]\n",
    "\n",
    "    # Create pivot tables for rel_bench_cost and std_cost\n",
    "    pivot_rel_bench = pd.pivot_table(\n",
    "        filtered_df,\n",
    "        values='rel_bench_avg_cost',\n",
    "        index=['scenario'],\n",
    "        columns=['week'],\n",
    "        aggfunc=\"first\"\n",
    "    )\n",
    "    \n",
    "    # Add the \"Average\" column, which contains the first value per scenario from \"rel_t_benchcost\"\n",
    "    average_values = filtered_df.groupby('scenario')['rel_t_bench_avg_cost'].first()\n",
    "    pivot_rel_bench['Total'] = average_values\n",
    "    \n",
    "    pivot_std = pd.pivot_table(\n",
    "        filtered_df,\n",
    "        values=f'rel_bench_std_cost',\n",
    "        index=['scenario'],\n",
    "        columns=['week'],\n",
    "        aggfunc=\"first\"\n",
    "    )\n",
    "    \n",
    "    # Add the \"Average\" column, which contains the first value per scenario from \"rel_t_benchcost\"\n",
    "    std_values = filtered_df.groupby('scenario')['rel_t_bench_std_cost'].first()\n",
    "    pivot_std['Total'] = std_values\n",
    "    # Add a new level to the index to distinguish between rel_bench_cost and std_cost\n",
    "    pivot_rel_bench['Metric'] = 'Cost Savings in %'\n",
    "    pivot_std['Metric'] = 'Standard Deviation'\n",
    "    \n",
    "    pivot_rel_bench.set_index('Metric', append=True, inplace=True)\n",
    "    pivot_std.set_index('Metric', append=True, inplace=True)\n",
    "\n",
    "    # Concatenate the two DataFrames to create a multi-index DataFrame\n",
    "    combined_pivot = pd.concat([pivot_rel_bench, pivot_std]).sort_index()\n",
    "\n",
    "\n",
    "    combined_pivot.to_excel(f\"../data/modelling_results/{path_name}.xlsx\")\n",
    "    \n",
    "    return combined_pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "987973a3-6a2c-4299-a525-6a598b0a89d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "weekly_p_evaluation_df = calc_weekly_robust_savings(p_robust_dict)\n",
    "scenario_pivot(weekly_p_evaluation_df, weekly_p_evaluation_df.model.unique()[1], path_name=\"tab_psi_scenario_table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce7fe2db-f2b4-4601-a686-df0f9454ae8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "weekly_c_evaluation_df = calc_weekly_robust_savings(c_robust_dict)\n",
    "scenario_pivot(weekly_c_evaluation_df, weekly_c_evaluation_df.model.unique()[1], path_name=\"tab_cost_scenario_table\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae71257-6cf9-4972-bd3f-94ef7f8d807e",
   "metadata": {},
   "source": [
    "# Scatterplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d871411-55a5-4255-ab48-6bee6414b25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize_model(model_name):\n",
    "    # Define the categories\n",
    "    classic = [\"sarima\", \"sarimax\", \"ets\", \"naive_seasonal\", \"naive_drift\"]\n",
    "    ml = [\"lgbm\", \"xgb\"]\n",
    "    dl = [\"lstm\", \"nhits\"]\n",
    "    \n",
    "    # Check for \"actual\" model\n",
    "    if model_name == \"actual\":\n",
    "        return \"Actual\"\n",
    "    \n",
    "    # Count occurrences of each model type\n",
    "    classic_count = sum(model_name.count(c) for c in classic)\n",
    "    ml_count = sum(model_name.count(m) for m in ml)\n",
    "    dl_count = sum(model_name.count(d) for d in dl)\n",
    "    \n",
    "    # Check for classic models\n",
    "    if classic_count > 0 and ml_count == 0 and dl_count == 0:\n",
    "        return \"Classic\"\n",
    "    \n",
    "    # Check for ML models\n",
    "    if ml_count > 0 and classic_count == 0 and dl_count == 0:\n",
    "        if model_name.count(\"lgbm\") > 1 or model_name.count(\"xgb\") > 1:\n",
    "            return \"Ensemble\"\n",
    "        return \"ML\"\n",
    "    \n",
    "    # Check for DL models\n",
    "    if dl_count > 0 and classic_count == 0 and ml_count == 0:\n",
    "        return \"DL\"\n",
    "    \n",
    "    # Check for ensemble models (combination of two or more models)\n",
    "    if classic_count + ml_count + dl_count > 1:\n",
    "        return \"Ensemble\"\n",
    "    \n",
    "    return \"unknown\"  # If the model doesn't fit any category\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f15d4f-2339-4c47-b809-782af39adf79",
   "metadata": {},
   "outputs": [],
   "source": [
    "ens_metrics = pd.read_excel(\"../data/modelling_results/ensemble_metrics_v2.xlsx\")\n",
    "\n",
    "# Merge the two DataFrames based on the model names\n",
    "merged_df = pd.merge(evaluation_df, ens_metrics, left_on='model', right_on='category')\n",
    "\n",
    "# Apply the function to the DataFrame\n",
    "merged_df['model_category'] = merged_df['model'].apply(categorize_model)\n",
    "\n",
    "# Get the val_rmse score for \"L_4_sarimax\" model\n",
    "sarimax_rmse = merged_df.loc[merged_df['model'] == \"L_4_sarimax\", 'pred_rmse'].values[0]\n",
    "\n",
    "# Set Seaborn style for an academic format\n",
    "sns.set(style=\"whitegrid\")\n",
    "sns.set_context(\"paper\")\n",
    "\n",
    "# Create the figure\n",
    "plt.figure(figsize=(15, 8))\n",
    "\n",
    "# Plot the regression line using sns.regplot\n",
    "sns.regplot(x='pred_rmse', y='mean_savings_bench', data=merged_df, scatter=False, line_kws={'color':'grey'})\n",
    "\n",
    "# Plot the points using sns.scatterplot\n",
    "sns.scatterplot(x='pred_rmse', y='mean_savings_bench', data=merged_df, hue=\"model_category\", s=20)\n",
    "\n",
    "# Draw a vertical line for the \"L_4_sarimax\" model's val_rmse score\n",
    "plt.axvline(sarimax_rmse, color='grey', linestyle='--')\n",
    "plt.annotate('Benchmark', xy=(sarimax_rmse, merged_df['mean_savings_bench'].max()), \n",
    "             xytext=(sarimax_rmse+50, merged_df['mean_savings_bench'].max()), \n",
    "             arrowprops=dict(facecolor='black', arrowstyle='->'),\n",
    "             horizontalalignment='left', verticalalignment='top', fontsize=10)\n",
    "\n",
    "# Calculate the correlation coefficient and p-value\n",
    "corr_coeff, p_value = pearsonr(merged_df['pred_rmse'], merged_df['mean_savings_bench'])\n",
    "\n",
    "# Annotate the plot with the correlation coefficient and p-value\n",
    "plt.annotate(f'Correlation: {corr_coeff:.2f}\\nP-value: {p_value:.4f}', \n",
    "             xy=(0.05, 0.95), xycoords='axes fraction', fontsize=12, verticalalignment='top')\n",
    "\n",
    "# Set labels and title for the plot\n",
    "plt.xlabel('Test RMSE', fontsize=12)\n",
    "plt.ylabel('Cost Savings Relative to Benchmark in %', fontsize=12)\n",
    "\n",
    "# Move the legend to the bottom right corner\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "# Display the plot\n",
    "plt.tight_layout()\n",
    "plt.savefig('../data/figures/scatter_rmse_cost.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b0b3f08-1d8e-48b0-92cc-6b71ec7ef4b7",
   "metadata": {},
   "source": [
    "## Scheduling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde74325-ef78-406d-aa58-8bf96f07016c",
   "metadata": {},
   "source": [
    "#### Planned workers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f0bfae-8cec-4727-b0cf-ae8c8dd88e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define excess function\n",
    "def excess_function(model, bench):\n",
    "\n",
    "    excess = np.round(((model - bench) / bench) * 100, 4)\n",
    "\n",
    "    return excess\n",
    "\n",
    "# Data (please keep this format)\n",
    "scenario = 1\n",
    "model = 'L_4_Time_Momentum_Lag_lgbm_L_4_Time_Momentum_Lag_Weather_xgb'\n",
    "benchmark_model = \"actual\"\n",
    "\n",
    "cost_excess = excess_function(np.sum(c_robust_dict[scenario][model][\"cost\"][:, :, :], axis=1).flatten(), \n",
    "                              np.sum(c_robust_dict[scenario][benchmark_model][\"cost\"][:, :, :], axis=1).flatten())\n",
    "\n",
    "wp_excess = excess_function(np.sum(c_robust_dict[scenario][model][\"w_p\"][:, :, :], axis=1).flatten(), \n",
    "                              np.sum(c_robust_dict[scenario][benchmark_model][\"w_p\"][:, :, :], axis=1).flatten())\n",
    "\n",
    "# Define the function y(x) based on the slopes and segments\n",
    "def y_func(x, segements):\n",
    "    for i in range(3):\n",
    "        lower_bound, upper_bound = segments[i]\n",
    "        if lower_bound <= x < upper_bound:\n",
    "            return slopes[i] * x + intercepts[i]\n",
    "    return 0  # Default value if x is out of all segments\n",
    "\n",
    "def plot_figures(mean, std_dev):\n",
    "    \n",
    "    def linear_func(x, a, b):\n",
    "        return a * x + b\n",
    "    \n",
    "    # Define the PDF of the normal distribution with mean (mean + s)\n",
    "    def pdf_shifted(x, mean, s, std_dev):\n",
    "        return (1 / (std_dev * np.sqrt(2 * np.pi))) * np.exp(-0.5 * ((x - (mean + s)) / std_dev)**2)\n",
    "\n",
    "    # Define the integrand for the expected value calculation with mean (mean + s)\n",
    "    def integrand_shifted(x, mean, s, std_dev, segments):\n",
    "        return y(x, segments) * pdf_shifted(x, mean, s, std_dev)\n",
    "\n",
    "    # Function to calculate the expected value (for minimizing)\n",
    "    def expected_value_to_minimize(s, mean, std_dev, segments):\n",
    "        expected_value, _ = quad(integrand_shifted, -np.inf, np.inf, args=(mean, s, std_dev, segments))\n",
    "        return expected_value\n",
    "\n",
    "    # Define the PDF of the standard normal distribution\n",
    "    def pdf(x, mean, std_dev):\n",
    "        return (1 / (std_dev * np.sqrt(2 * np.pi))) * np.exp(-0.5 * ((x - mean) / std_dev)**2)\n",
    "\n",
    "\n",
    "    # Define the integrand for the expected value calculation\n",
    "    def integrand(x, std_dev, segments):\n",
    "        return y(x, segments) * pdf(x, std_dev)\n",
    "    \n",
    "    # Define boundry overtime boundry\n",
    "    def overtime_boundry(p_o, p_p):\n",
    "        \n",
    "        # overtime equivilant to planned workers \n",
    "        p_op = (1+(p_o-p_p)/p_p)\n",
    "        \n",
    "        # 0.2 = shitft length, return in %\n",
    "        boundry = (1/(0.2*p_op+1)-1)*100\n",
    "        \n",
    "        print(f\"Boundry at: {boundry} excess planned workers\")\n",
    "        \n",
    "        return boundry\n",
    "    \n",
    "    slopes = {}\n",
    "    intercepts = {}\n",
    "    segments = {}\n",
    "    segments[0] = (-100, overtime_boundry(11,12)) \n",
    "    segments[1] = (overtime_boundry(11,12), 0) \n",
    "    segments[2] = (0, 100)\n",
    "\n",
    "    # Loop through each segment and fit a linear model\n",
    "    for i in range(3):\n",
    "        lower_bound, upper_bound = segments[i]\n",
    "        mask = (wp_excess > lower_bound) & (wp_excess <= upper_bound)\n",
    "        x_data, y_data = wp_excess[mask], cost_excess[mask]\n",
    "        popt, _ = curve_fit(linear_func, x_data, y_data)\n",
    "        slopes[i], intercepts[i] = popt[0], popt[1] \n",
    "        \n",
    "        print(f\"Slope {i}: {slopes[i]}, Intercept: {intercepts[i]}\")\n",
    "\n",
    "    # Define the function y(x) based on the slopes and segments\n",
    "    def y(x, segments):\n",
    "        for i in range(3):\n",
    "            lower_bound, upper_bound = segments[i]\n",
    "            if lower_bound <= x < upper_bound:\n",
    "                return slopes[i] * x + intercepts[i]\n",
    "        return 0  # Default value if x is out of all segments\n",
    "\n",
    "    # Minimize the expected value\n",
    "    result = minimize_scalar(expected_value_to_minimize, args=(mean, std_dev, segments))\n",
    "    optimal_s = result.x\n",
    "    min_expected_value = result.fun\n",
    "    \n",
    "    # Calculate the expected value for s=0\n",
    "    expected_value_s_zero = expected_value_to_minimize(0, mean, std_dev, segments)\n",
    "    \n",
    "    # Minimize the expected value for example\n",
    "    result_0 = minimize_scalar(expected_value_to_minimize, args=(0, std_dev, segments))\n",
    "    optimal_s_0 = result_0.x\n",
    "    min_expected_value_0 = result_0.fun\n",
    "    # Calculate the expected value for s=0\n",
    "    expected_value_s_0_zero = expected_value_to_minimize(0, 0, std_dev, segments)\n",
    "    \n",
    "    # Generate data for plotting\n",
    "    x_values = np.linspace(-65, 30, 500)\n",
    "    y_values = [y(x, segments) for x in x_values]\n",
    "    pdf_values = pdf(x_values, mean, std_dev)  # Now using custom_mean\n",
    "    \n",
    "    # generate 0,10 case \n",
    "    \n",
    "    # Generate data for plotting\n",
    "    x_values = np.linspace(-65, 30, 500)\n",
    "    y_values = [y(x, segments) for x in x_values]\n",
    "    pdf_values_0 = pdf(x_values, 0, 10)  # Now using custom_mean\n",
    "    \n",
    "    # Plotting\n",
    "    plt.figure(figsize=(18, 6))\n",
    "\n",
    "    # Original y(x) and PDF\n",
    "    plt.subplot(1, 5, 1)\n",
    "    plt.scatter(wp_excess, cost_excess, color = \"lightgrey\")\n",
    "    plt.plot(x_values, y_values, color=\"grey\")\n",
    "    plt.title('Scatter and Value Function')\n",
    "    plt.xlabel('Excess Planned Workers in %')\n",
    "    plt.ylabel('Excess Cost in %')\n",
    "\n",
    "    plt.subplot(1, 5, 2)\n",
    "    plt.plot(x_values, pdf_values_0, color=\"grey\")\n",
    "    plt.title(f'PDF of Normal Dist. with mean {0:.2f} and std {std_dev:.2f}')\n",
    "    plt.xlabel('Excess Planned Workers in %')\n",
    "    plt.ylabel('Probability Density')\n",
    "\n",
    "    # Expected value of y for different s\n",
    "    plt.subplot(1, 5, 3)\n",
    "    s_values = np.linspace(-2 * optimal_s-5, 2 * optimal_s+5, 100)\n",
    "    expected_values = [expected_value_to_minimize(s, 0, std_dev, segments) for s in s_values]\n",
    "    plt.plot(s_values, expected_values, color=\"grey\")\n",
    "    plt.title('Expected Value of Excess Cost for Different s')\n",
    "    plt.xlabel('s - Location Parameter (Shifting Norm Distribution with Mean-s)')\n",
    "    plt.ylabel('E[Excess Cost] in %')\n",
    "\n",
    "    plt.subplot(1, 5, 4)\n",
    "    plt.plot(x_values, pdf_values, color=\"grey\")\n",
    "    plt.title(f'PDF of Actual Normal Dist. with Mean {mean:.2f} and Std {std_dev:.2f}')\n",
    "    plt.xlabel('Excess Planned Workers in %')\n",
    "    plt.ylabel('Probability Density')\n",
    "\n",
    "    # Expected value of y for different s\n",
    "    plt.subplot(1, 5, 5)\n",
    "    s_values = np.linspace(-2 * optimal_s-5, 2 * optimal_s+5, 100)\n",
    "    expected_values = [expected_value_to_minimize(s, mean, std_dev, segments) for s in s_values]\n",
    "    plt.plot(s_values, expected_values, color=\"grey\")\n",
    "    plt.title(f'Expected Value of Excess Cost for Different s')\n",
    "    plt.xlabel('s - Location Parameter (Shifting Norm Distribution with Mean-s)')\n",
    "    plt.ylabel('E[Excess Cost] in %')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'../data/figures/excess_schedulling.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"Tht expected value of y with mean = 0. and without s is approximately {expected_value_s_0_zero:.4f}\")\n",
    "    print(f\"The value of s that minimises E[excess cost] is approximately {optimal_s_0:.4f}\")\n",
    "    print(f\"The min expected value of y is approximately {min_expected_value_0:.4f}\")\n",
    "    \n",
    "    print(f\"Tht expected value of y without actual mean s is approximately {expected_value_s_zero:.4f}\")\n",
    "    print(f\"The value of s that minimises E[exces cost] is approximately {optimal_s:.4f}\")\n",
    "    print(f\"The min expected value of y is approximately {min_expected_value:.4f}\")\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "# Standard deviation and mean of wp_excess\n",
    "std_dev = np.std(wp_excess)\n",
    "mean = np.mean(wp_excess)\n",
    "    \n",
    "# Call the function with your custom mean and std_dev\n",
    "plot_figures(mean, std_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6460f921-8704-4561-a23a-dc7e0125289b",
   "metadata": {},
   "source": [
    "## Weekly Savings Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c3f4e2a-7873-4cdc-a9ff-c0c9e77b2737",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select data\n",
    "model_data = np.sum(single_dict[evaluation_df.reset_index().model[1]][\"cost\"], axis=1).flatten()\n",
    "bench_data = np.sum(single_dict[benchmark_model][\"cost\"], axis=1).flatten()\n",
    "\n",
    "# Calculate relative performance for each week and total\n",
    "# weekly\n",
    "rel_per_weekly = []\n",
    "for week in range(7):\n",
    "    model_week = np.sum(single_dict[evaluation_df.reset_index().model[1]][\"cost\"][week,:,:], axis=0)\n",
    "    bench_week = np.sum(single_dict[benchmark_model][\"cost\"][week,:,:], axis=0)\n",
    "    rel_per = np.round((((model_week - bench_week) / bench_week) * 100), 2)\n",
    "    rel_per_weekly.append(rel_per)\n",
    "    \n",
    "    print(week, np.round(np.median(rel_per),2))\n",
    "    \n",
    "# total\n",
    "rel_t_per_bench = np.round((((model_data - bench_data) / bench_data) * 100), 2)\n",
    "print(\"Total Median :\", np.round(np.median(rel_t_per_bench),2))\n",
    "print(\"Total Mean :\", np.round(np.mean(rel_t_per_bench),2))\n",
    "\n",
    "median_saving = np.round(np.median(rel_per_bench),2)\n",
    "# Combine weekly and total data for boxplot\n",
    "all_data = rel_per_weekly + [rel_t_per_bench]\n",
    "\n",
    "# Create a figure\n",
    "plt.figure(figsize=(15, 8))\n",
    "\n",
    "# Create a subplot for the boxplot (1 row, 1 column, first plot)\n",
    "plt.subplot(1, 1, 1)\n",
    "box = plt.boxplot(all_data, vert=True, patch_artist=True, labels=[f\"Week {i+1}\" for i in range(7)] + [\"Total\"])\n",
    "plt.xlabel('Time Period')\n",
    "plt.ylabel('Weekly Workforce Costs of Best Model Relative to Benchmark in %')\n",
    "plt.grid(True)\n",
    "\n",
    "# Change the color of the boxplot to grey\n",
    "for patch in box['boxes']:\n",
    "    patch.set_facecolor('white')\n",
    "\n",
    "# Annotate median values\n",
    "for i, median in enumerate(box['medians']):\n",
    "    median_x = []\n",
    "    median_y = []\n",
    "    for point in median.get_data()[1]:\n",
    "        median_x.append(i + 1)\n",
    "        median_y.append(point)\n",
    "    plt.annotate(f'Median: {median_y[0]:.2f}', xy=(median_x[0], median_y[0]), xytext=(median_x[0]-0.22, median_y[0]+0.2),\n",
    "                 fontsize=9)\n",
    "\n",
    "# Show the plots\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'../data/figures/box_savings.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c55b86-df55-4068-9844-fd7f60616518",
   "metadata": {},
   "source": [
    "### Amount of planned workers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "808e769e-5153-4daf-9252-286c67fdc4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty list to store the data\n",
    "data_list = []\n",
    "\n",
    "# Select data\n",
    "for model in c_robust_dict[0].keys():\n",
    "    for week in range(7):\n",
    "        amount_planned_workers = np.mean(np.sum(c_robust_dict[1][model][\"w_p\"][week, :, :], axis=0).flatten())\n",
    "        \n",
    "        # Add week number, model name, and number of planned workers to list\n",
    "        data_list.append([week+1, model, amount_planned_workers])\n",
    "\n",
    "# Create a DataFrame from the list\n",
    "planned_workers_df = pd.DataFrame(data_list, columns=['week', 'model', 'amount_planned_workers'])\n",
    "\n",
    "# Plot\n",
    "filtered_df = planned_workers_df.copy()\n",
    "\n",
    "# Scale the 'amount_planned_workers' column between 0 and 1\n",
    "scaler = MinMaxScaler()\n",
    "filtered_df['scaled_planned_workers'] = scaler.fit_transform(filtered_df[['amount_planned_workers']])\n",
    "\n",
    "# Set Seaborn style for an academic format\n",
    "sns.set(style=\"whitegrid\")\n",
    "sns.set_context(\"paper\")\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(15, 6))\n",
    "sns.lineplot(data=filtered_df, x='week', y='scaled_planned_workers', hue='model', marker='o')\n",
    "\n",
    "# Setting title and labels\n",
    "plt.xlabel('Week')\n",
    "plt.ylabel('Scaled Average Amount of Planned Workers per Week (0-1)')\n",
    "plt.legend(title='Model')\n",
    "\n",
    "# Display the plot\n",
    "plt.tight_layout()\n",
    "plt.savefig('../data/figures/planned_workers_week_lgbm.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a74e6fb3-4b6a-4ada-9e21-343ab5430b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Initialize an empty list to store the data\n",
    "data_list = []\n",
    "\n",
    "# Initialize variables to keep track of the overall min and max values of w_p\n",
    "overall_min = np.inf\n",
    "overall_max = -np.inf\n",
    "\n",
    "# Loop through each model and week to collect data\n",
    "for model in c_robust_dict[0].keys():\n",
    "    for week in range(7):\n",
    "        \n",
    "        amount_planned_workers = np.sum(c_robust_dict[0][model][\"w_p\"][week, :, :], axis=0).flatten() - np.sum(c_robust_dict[0][\"actual\"][\"w_p\"][week, :, :], axis=0).flatten()\n",
    "        \n",
    "        # Update overall min and max\n",
    "        overall_min = min(overall_min, np.min(amount_planned_workers))\n",
    "        overall_max = max(overall_max, np.max(amount_planned_workers))\n",
    "        \n",
    "        # Add week number, model name, and amount of planned workers to list\n",
    "        for val in amount_planned_workers:\n",
    "            data_list.append([week+1, model, val])\n",
    "\n",
    "# Create a DataFrame from the list\n",
    "planned_workers_df = pd.DataFrame(data_list, columns=['week', 'model', 'amount_planned_workers'])\n",
    "\n",
    "# Scale the 'amount_planned_workers' column between overall_min and overall_max\n",
    "# Find the absolute maximum value among the overall minimum and maximum values\n",
    "abs_max = max(abs(overall_min), abs(overall_max))\n",
    "\n",
    "# Conditionally scale the 'amount_planned_workers' column between -1 and 1\n",
    "planned_workers_df['scaled_planned_workers'] = planned_workers_df['amount_planned_workers'].apply(lambda x: x / abs_max if abs_max != 0 else 0)\n",
    "\n",
    "\n",
    "\n",
    "# Set Seaborn style for an academic format\n",
    "sns.set(style=\"whitegrid\")\n",
    "sns.set_context(\"paper\")\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(15, 6))\n",
    "\n",
    "# Create boxplots\n",
    "ax = sns.boxplot(data=planned_workers_df, x='week', y='scaled_planned_workers', hue='model', palette=\"Greys\")\n",
    "\n",
    "# Setting title and labels\n",
    "plt.xlabel('Week')\n",
    "plt.ylabel('Scaled Sum of Planned Workers per Model per Week Relative to Perfect Model')\n",
    "\n",
    "# Get the handles and labels from Seaborn's boxplot\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "\n",
    "# Define your custom labels\n",
    "custom_labels = ['Perfect', 'Best', 'Benchmark']\n",
    "\n",
    "# Set the custom legend\n",
    "plt.legend(handles, custom_labels, title='Model')\n",
    "\n",
    "# Display the plot\n",
    "plt.tight_layout()\n",
    "plt.savefig('../data/figures/box_planned_workers_week_lgbm.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e057b032-fb29-44c6-bb78-a86c84993ee6",
   "metadata": {},
   "source": [
    "## Overcapacity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ceb48f-1410-4a81-8ae2-ffb9ffa9bd67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty list to store the data\n",
    "data_list = []\n",
    "\n",
    "# Initialize variables to keep track of the overall min and max values of w_p\n",
    "overall_min = np.inf\n",
    "overall_max = -np.inf\n",
    "\n",
    "# Loop through each model and week to collect data\n",
    "for model in c_robust_dict[0].keys():\n",
    "    for week in range(7):\n",
    "        \n",
    "        amount_planned_workers = np.sum(c_robust_dict[0][model][\"v\"][week, :, :], axis=0).flatten()\n",
    "        \n",
    "        # Update overall min and max\n",
    "        overall_min = min(overall_min, np.min(amount_planned_workers))\n",
    "        overall_max = max(overall_max, np.max(amount_planned_workers))\n",
    "        \n",
    "        # Add week number, model name, and amount of planned workers to list\n",
    "        for val in amount_planned_workers:\n",
    "            data_list.append([week+1, model, val])\n",
    "\n",
    "# Create a DataFrame from the list\n",
    "planned_workers_df = pd.DataFrame(data_list, columns=['week', 'model', 'amount_overcapacity'])\n",
    "\n",
    "# Scale the 'amount_planned_workers' column between overall_min and overall_max\n",
    "planned_workers_df['scaled_overcapacity'] = (planned_workers_df['amount_overcapacity'] - overall_min) / (overall_max - overall_min)\n",
    "\n",
    "# Set Seaborn style for an academic format\n",
    "sns.set(style=\"whitegrid\")\n",
    "sns.set_context(\"paper\")\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(15, 6))\n",
    "\n",
    "# Create boxplots\n",
    "ax = sns.boxplot(data=planned_workers_df, x='week', y='scaled_overcapacity', hue='model', palette=\"Greys\")\n",
    "\n",
    "# Setting title and labels\n",
    "plt.xlabel('Week')\n",
    "plt.ylabel('Scaled Sum of Overcapcity per Model per Week')\n",
    "\n",
    "# Get the handles and labels from Seaborn's boxplot\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "\n",
    "# Define your custom labels\n",
    "custom_labels = ['Perfect', 'Best', 'Benchmark']\n",
    "\n",
    "# Set the custom legend\n",
    "plt.legend(handles, custom_labels, title='Model')\n",
    "\n",
    "# Display the plot\n",
    "plt.tight_layout()\n",
    "plt.savefig('../data/figures/box_overcapacity_week_lgbm.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0221ca5-0ff5-4e7d-9c70-aafd73212b99",
   "metadata": {},
   "source": [
    "## Boxplot per week per scenario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6366c96b-cc7c-44e9-b15d-c450d1af96c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cost_boxplot(robust_dict, scenario_label=[\"0.7\", \"0.8\", \"0.9\"], path_name = \"box_cost_p_scenario_comparison\"):\n",
    "    variable = \"cost\"\n",
    "    # Initialize an empty list to store the data\n",
    "    data_list = []\n",
    "    \n",
    "    # Model and Benchmark\n",
    "    model = 'L_4_Time_Momentum_Lag_lgbm_L_4_Time_Momentum_Lag_Weather_xgb'\n",
    "    benchmark_model = \"L_4_sarimax\"\n",
    "    \n",
    "    for week in range(7):  # Loop through each week\n",
    "        for scenario in robust_dict.keys():  # Loop through each scenario\n",
    "            weekly_model_data = np.sum(robust_dict[scenario][model][variable][week, :, :], axis=0)\n",
    "            weekly_bench_data = np.sum(robust_dict[scenario][benchmark_model][variable][week, :, :], axis=0)\n",
    "            \n",
    "            rel_per = np.round((((weekly_model_data - weekly_bench_data)/ weekly_bench_data) * 100), 2)\n",
    "            \n",
    "            # Append week number, scenario, and relative percentage to list\n",
    "            for val in rel_per:\n",
    "                data_list.append([week+1, scenario, val])\n",
    "    \n",
    "    # Create a DataFrame from the list\n",
    "    df = pd.DataFrame(data_list, columns=['week', 'scenario', 'rel_per'])\n",
    "    \n",
    "    # Set Seaborn style for an academic format\n",
    "    sns.set(style=\"whitegrid\")\n",
    "    sns.set_context(\"paper\")\n",
    "    \n",
    "    # Plotting\n",
    "    plt.figure(figsize=(15, 6))\n",
    "    \n",
    "    # Create boxplots\n",
    "    ax = sns.boxplot(data=df, x='week', y='rel_per', hue='scenario', palette=\"Greys\")\n",
    "\n",
    "    \n",
    "    # Setting title and labels\n",
    "    plt.xlabel('Week')\n",
    "    plt.ylabel('Relative Costs to Benchmark in %')\n",
    "    \n",
    "    # Get the handles and labels from Seaborn's boxplot\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    \n",
    "    # Set the custom legend\n",
    "    plt.legend(handles, scenario_label, title='Scenario')\n",
    "    \n",
    "    plt.grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'../data/figures/{path_name}.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "# Example usage\n",
    "\n",
    "create_cost_boxplot(c_robust_dict, scenario_label=[\"-2\", \"0\", \"2\"], path_name=\"box_cost_c_scenario_comparison\")\n",
    "create_cost_boxplot(p_robust_dict, scenario_label=[\"0.7\", \"0.8\", \"0.9\"], path_name = \"box_cost_p_scenario_comparison\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b4f286e-5014-4a32-8000-9dd930898f9a",
   "metadata": {},
   "source": [
    "## Boxplots per variable per scenario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2372a1a-79b3-4f38-837a-dddfffb67757",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_data(data):\n",
    "    scaler = MinMaxScaler()\n",
    "    return scaler.fit_transform(data.reshape(-1, 1)).flatten()\n",
    "\n",
    "def create_boxplot(robust_dict, model_label=[\"Perfect\", \"Best Model\", \"Benchmark\"], scenario_label=[\"-2\", \"0\", \"+2\"], path_name=\"box_test\"):\n",
    "    \n",
    "    # Initialize the figure\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(15, 6))\n",
    "\n",
    "    # Flatten the axes for easier indexing\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    # Define flier properties for boxplot\n",
    "    flierprops = dict(marker='o', markerfacecolor='white', markersize=2, linestyle='none')\n",
    "    \n",
    "    models = robust_dict[0].keys()\n",
    "    # Loop through variables and names\n",
    "    for i, (variable, name) in enumerate(zip(variables, variables_name)):\n",
    "\n",
    "        all_data = []\n",
    "        xticklabels = []\n",
    "        model_labels = []\n",
    "        collected_data = []\n",
    "\n",
    "        # Collect all data for this variable across all models and scenarios\n",
    "        for model in models:\n",
    "            print(model)\n",
    "            for scenario in robust_dict.keys():\n",
    "                data = np.sum(robust_dict[scenario][model][variable], axis=1).flatten()\n",
    "                collected_data.append(data)\n",
    "\n",
    "        # Convert list of arrays to a single numpy array\n",
    "        collected_data = np.concatenate(collected_data)\n",
    "\n",
    "        # Scale the collected data\n",
    "        collected_data_scaled = scale_data(collected_data)\n",
    "\n",
    "        # Loop through models and scenarios\n",
    "        start_idx = 0\n",
    "        for model_idx, model in enumerate(models):\n",
    "            for scenario_idx, scenario in enumerate(robust_dict.keys()):\n",
    "                # Extract and flatten data\n",
    "                data = np.sum(robust_dict[scenario][model][variable], axis=1).flatten()\n",
    "                end_idx = start_idx + len(data)\n",
    "\n",
    "                # Get the corresponding scaled data\n",
    "                data_scaled = collected_data_scaled[start_idx:end_idx]\n",
    "                start_idx = end_idx\n",
    "\n",
    "                # Append to all_data for boxplot\n",
    "                all_data.append(data_scaled)\n",
    "\n",
    "                # Append scenario label to xticklabels\n",
    "                xticklabels.append(scenario_label[scenario_idx])\n",
    "\n",
    "            # Append model label to model_labels\n",
    "            model_labels.append(model_label[model_idx])\n",
    "\n",
    "        # Create the boxplot on the appropriate subplot\n",
    "        box = axes[i].boxplot(all_data, patch_artist=True, flierprops=flierprops)\n",
    "\n",
    "        # Change the color of the boxplot to grey\n",
    "        for patch in box['boxes']:\n",
    "            patch.set_facecolor('white')\n",
    "            \n",
    "        \n",
    "        # Set xticks and xticklabels\n",
    "        axes[i].set_xticks(np.arange(1, len(xticklabels) + 1))\n",
    "        axes[i].set_xticklabels(xticklabels, rotation=0, ha=\"center\", fontsize=8)\n",
    "\n",
    "        # Add second line of xticks for model names\n",
    "        for j, model in enumerate(model_labels):\n",
    "            start = len(robust_dict.keys()) * j + 1\n",
    "            end = len(robust_dict.keys()) * (j + 1)\n",
    "            pos = np.mean([start, end])\n",
    "            axes[i].text(pos, -0.2, model, ha='center', va='top', fontsize=8)\n",
    "\n",
    "        # Set title\n",
    "        axes[i].set_title(f\"Scaled sum of {name}\")\n",
    "    \n",
    "    # add final legend that statest: Best Model: Ensemble of Customer LGBM and Customer xGBM-Weather\n",
    "    #fig.legend(labels=[\"Best Model: Ensemble of Customer LGBM and Customer xGBM-Weather\"], loc=\"upper right\")\n",
    "\n",
    "    # Show the plot\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'../data/figures/{path_name}.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "# Your code to populate c_robust_dict goes here\n",
    "psi_box = create_boxplot(p_robust_dict, scenario_label=[\"0.7\", \"0.8\", \"0.9\"], path_name=\"psi_box\" )\n",
    "cost_box = create_boxplot(c_robust_dict, path_name=\"cost_box\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:miniconda3-snowflakes]",
   "language": "python",
   "name": "conda-env-miniconda3-snowflakes-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
