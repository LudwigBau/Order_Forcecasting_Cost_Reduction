{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a894b9f-ecc9-4318-a484-7c7ff38a6163",
   "metadata": {},
   "source": [
    "# Goals\n",
    "\n",
    "1. Create Metrics DF with all errorterms from all models\n",
    "    - Structure: Index = Modelname + Category, Columns = Error Metric + Horizon, Values=Metrics\n",
    "    \n",
    "    \n",
    "2. Create Value DF with all forecasts from all models \n",
    "    - Structure: Index = Date, Columns = Modelname, Values=Forecasts "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba5fbb9d-afef-414d-8963-08520adc0f56",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93b5a18-3d66-4d0b-a225-84d9a01eeeaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# library\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import mean_absolute_percentage_error as mape\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "\n",
    "from itertools import combinations\n",
    "# Get custom utils functions\n",
    "import sys\n",
    "sys.path.append('/Users/ludwigbaunach/Documents/Studium/PhD/Alaiko/Paper_1_Project/Main/src')\n",
    "\n",
    "from utils.data_split import ml_data_date_split\n",
    "from utils.model_utils import rmse as RMSE\n",
    "from utils.evaluation_of_df_ts import create_error_dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3610e90e-a74c-4096-9385-b552bbe90a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data \n",
    "L_3 = pd.read_pickle(\"../data/processed/L_3_test.pkl\")\n",
    "\n",
    "# time series\n",
    "ts_results = pd.read_pickle(\"../data/modelling_results/ts_results_all.pickle\")\n",
    "\n",
    "lgbm_results = pd.read_pickle(\"../data/modelling_results/lgbm_results.pickle\")\n",
    "lgbm_results_s = pd.read_pickle(\"../data/modelling_results/lgbm_results_selected_f.pickle\")\n",
    "lgbm_params = pd.read_pickle(\"../data/modelling_results/lgbm_params.pickle\")\n",
    "lgbm_importance = pd.read_pickle(\"../data/modelling_results/lgbm_importance.pickle\")\n",
    "\n",
    "# xgb\n",
    "xgb_results = pd.read_pickle(\"../data/modelling_results/xgb_results.pickle\")\n",
    "xgb_params = pd.read_pickle(\"../data/modelling_results/xgb_params.pickle\")\n",
    "xgb_importance = pd.read_pickle(\"../data/modelling_results/xgb_importance.pickle\")\n",
    "\n",
    "# LSTM\n",
    "lstm_results = pd.read_pickle(\"../data/modelling_results/lstm_results.pickle\")\n",
    "# nhits\n",
    "\n",
    "nhits_results = pd.read_pickle(\"../data/modelling_results/nhits_results.pickle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc8fe9b-75fb-4e7b-a9b6-37962d2407a3",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Explore Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee560b6d-f2ef-45b0-9fe5-793036a71092",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_results.keys()\n",
    "#lgbm_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7019f22f-f7f5-4315-a5f9-b68ab3b5a964",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_results.keys()\n",
    "#ts_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65cccaa-1cb0-424c-8f84-d6ca4ea767f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_results.keys()\n",
    "lstm_results[\"L_6\"][\"backtest\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "508f8d64-ff88-4896-8a7d-a0076191a638",
   "metadata": {},
   "outputs": [],
   "source": [
    "nhits_results.keys()\n",
    "nhits_results[\"L_6\"][\"backtest\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada13832-1339-4cab-9464-36658bac09b4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Individual Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09aae3a7-a012-4cf9-8c5a-9f58a75fb52a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### ts_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa5fe72-185a-4873-a5ba-b18bcd33933f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example\n",
    "ts_model_names = ts_results[\"L_3\"][\"pred\"].columns[0:5]\n",
    "ts_model_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49467ffb-6de0-4f0e-84d7-c30ce285309f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_rmse_mape(true_values, predicted_values):\n",
    "    \n",
    "    rmse_score = np.sqrt(mse(true_values, predicted_values))\n",
    "    mape_score = mape(true_values, predicted_values)\n",
    "    \n",
    "    return rmse_score, mape_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de3dbca-8bd6-4ce0-b990-e1b2232de90b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_error_df_ts(ts_results, lgbm_results):\n",
    "    data = []\n",
    "    index = []\n",
    "    # Loop through categories\n",
    "    for category_name, _ in ts_results.items():\n",
    "        # Get model names\n",
    "        ts_model_names = ts_results[category_name][\"pred\"].columns[0:5]\n",
    "        \n",
    "        for model_name in ts_model_names:\n",
    "            # Access backtest and prediction data frame for the current level and category\n",
    "            ts_backtest = ts_results[category_name]['backtest'].reset_index().groupby([\"index\"]).sum()\n",
    "            ts_pred = ts_results[category_name]['pred'].reset_index().groupby([\"index\"]).sum()\n",
    "\n",
    "            # Access actual values for backtest and prediction\n",
    "            back_actual = lgbm_results[\"L_3_Time_Momentum_Lag\"][\"backtest\"].groupby([\"date\"]).sum().actual\n",
    "            pred_actual = lgbm_results[\"L_3_Time_Momentum_Lag\"][\"pred\"].groupby([\"date\"]).sum().actual\n",
    "\n",
    "            # Calculate RMSE and MAPE for backtest\n",
    "            rmse_backtest, mape_backtest = calculate_rmse_mape(back_actual, ts_backtest[model_name])\n",
    "\n",
    "            # Calculate RMSE and MAPE for forecast\n",
    "            rmse_pred, mape_pred = calculate_rmse_mape(pred_actual, ts_pred[model_name])\n",
    "\n",
    "            data.append([rmse_backtest, rmse_pred, mape_backtest, mape_pred])\n",
    "            index.append(f\"{category_name}_{model_name}\")\n",
    "\n",
    "    # Create column names\n",
    "    columns = [f\"val_rmse\", f\"pred_rmse\", f\"val_mape\", f\"pred_mape\"]\n",
    "\n",
    "    # Create the DataFrame\n",
    "    df = pd.DataFrame(data, columns=columns, index=index)\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "922e1f08-2c69-4e58-901f-072a21261683",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_error = create_error_df_ts(ts_results, lgbm_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad6a5a49-a2bb-4e4c-9fca-d1da41f3a14e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_error.sort_values(\"pred_rmse\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "996d328a-c606-4c7a-b4db-68c39254fa1b",
   "metadata": {
    "tags": []
   },
   "source": [
    "### lgbm_resuts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d7fd50e-c199-4ba5-99ed-c6d1a9098bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# params\n",
    "#params_df = pd.DataFrame.from_dict(lgb_params, orient=\"index\")\n",
    "# save as exel\n",
    "#params_df.to_excel(\"../data/modelling_results/lgbm_params.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0022d951-cff4-4828-80c7-bbcde3e7cfb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_error_df_tree(tree_results):\n",
    "    # Initialize an empty list to store the results\n",
    "    metrics_data = []\n",
    "\n",
    "    # Iterate over the dataframes and categories\n",
    "\n",
    "    for category_name, _ in tree_results.items():\n",
    "        # Access backtest data frame for the current level and category\n",
    "        backtest = tree_results[f\"{category_name}\"]['backtest'].groupby(\"date\").sum()\n",
    "        # Access prediction data frame for the current level and category\n",
    "        pred = tree_results[f\"{category_name}\"]['pred'].groupby(\"date\").sum()\n",
    "\n",
    "        # Calculate RMSE\n",
    "        val_rmse = np.sqrt(mse(backtest.actual, backtest.pred))\n",
    "        pred_rmse = np.sqrt(mse(pred.actual, pred.pred))\n",
    "\n",
    "        # Calculate MAPE\n",
    "        val_mape = mape(backtest.actual, backtest.pred)\n",
    "        pred_mape = mape(pred.actual, pred.pred)\n",
    "\n",
    "        # Calculate MAE\n",
    "        val_mae = mae(backtest.actual, backtest.pred)\n",
    "        pred_mae = mae(pred.actual, pred.pred)\n",
    "\n",
    "        # Append the results to the metrics_data list\n",
    "        metrics_data.append({\n",
    "            'category': category_name,\n",
    "            'val_rmse': val_rmse,\n",
    "            'pred_rmse': pred_rmse,\n",
    "            'val_mape': val_mape,\n",
    "            'pred_mape': pred_mape,\n",
    "            #'val_mae': val_mae,\n",
    "            #'pred_mae': pred_mae\n",
    "        })\n",
    "        \n",
    "        lgbm_metrics = pd.DataFrame(metrics_data)\n",
    "        \n",
    "    return lgbm_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e3cb8a-f621-485d-a053-6e0912a4ba96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lgbm errors\n",
    "lgbm_error = create_error_df_tree(lgbm_results) #.sort_values(\"val_rmse\")\n",
    "lgbm_error.sort_values(\"pred_rmse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec988522-cce3-467d-8ce5-2164cfc9d489",
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgb error\n",
    "xgb_error = create_error_df_tree(xgb_results) \n",
    "xgb_error.sort_values(\"pred_rmse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c7a9f6c-b51d-4f2d-88bb-f7df6ae8491a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to excel \n",
    "#df_metrics.to_excel(\"../data/modelling_results/lgbm_metrics.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d335520-014e-467a-bbd9-fee74f9cfa28",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lstm_results[\"L_6\"][\"backtest\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dfd913a-fb19-46a8-a66b-7bf9d73cad63",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Deep Learning Errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01076f43-712e-4fb4-b232-945689a16231",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_error_df_dl(dl_results, lgbm_results, model_name):\n",
    "    \n",
    "    data = []\n",
    "    index = []\n",
    "    # Loop through categories\n",
    "    for category_name, _ in dl_results.items():\n",
    "\n",
    "        # Access backtest and prediction data frame for the current level and category\n",
    "        dl_backtest = dl_results[category_name]['backtest'].groupby([\"date\"]).sum().pred\n",
    "        dl_pred = dl_results[category_name]['pred'].groupby([\"date\"]).sum().pred\n",
    "\n",
    "        # Access actual values for backtest and prediction\n",
    "        back_actual = lgbm_results[\"L_3_Time_Momentum_Lag\"][\"backtest\"].groupby([\"date\"]).sum().actual\n",
    "        pred_actual = lgbm_results[\"L_3_Time_Momentum_Lag\"][\"pred\"].groupby([\"date\"]).sum().actual\n",
    "        \n",
    "        # Calculate RMSE and MAPE for backtest\n",
    "        rmse_backtest, mape_backtest = calculate_rmse_mape(back_actual, dl_backtest)\n",
    "\n",
    "        # Calculate RMSE and MAPE for forecast\n",
    "        rmse_pred, mape_pred = calculate_rmse_mape(pred_actual, dl_pred)\n",
    "\n",
    "        data.append([rmse_backtest, rmse_pred, mape_backtest, mape_pred])\n",
    "        index.append(f\"{category_name}_{model_name}\")\n",
    "\n",
    "    # Create column names\n",
    "    columns = [f\"val_rmse\", f\"pred_rmse\", f\"val_mape\", f\"pred_mape\"]\n",
    "\n",
    "    # Create the DataFrame\n",
    "    df = pd.DataFrame(data, columns=columns, index=index)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd60ec6-d094-4085-a764-b99733ca06dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_error = create_error_df_dl(lstm_results, lgbm_results, \"lstm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5592c339-41d1-4182-b925-b788a64b2a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "nhits_error = create_error_df_dl(nhits_results, lgbm_results, \"nhits\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040d3e29-c0f3-4293-bcdd-04c171dff7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "nhits_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c66bd500-c761-45e3-9b86-d1bfad789e9e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Ensemble  Metrics\n",
    "\n",
    "Method:\n",
    "\n",
    "- Select best model per level: L 6,5,4,3,2,\n",
    "- select SARIMAX ARIMA and ES\n",
    "\n",
    "- make combinations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65fcce01-5fdf-4a7a-b2a9-6cbf1c0a5cbe",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Custom functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa6e12c-29c1-4cf5-9213-b2a8bead78d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def back_pred_df(ts_results, lgbm_results, xgb_results, lstm_results, nhits_results):\n",
    "    \n",
    "    # Lists to hold 'pred' series\n",
    "    backtest_list = []\n",
    "    pred_list = []\n",
    "    \n",
    "    # ts\n",
    "    for key in ts_results.keys():\n",
    "        for column in ts_model_names:\n",
    "            backtest_series = ts_results[key]['backtest'].reset_index().groupby([\"index\"]).sum()[column]\n",
    "            pred_series  = ts_results[key]['pred'].reset_index().groupby([\"index\"]).sum()[column]\n",
    "\n",
    "            # Rename the series to the current key and column\n",
    "            backtest_series.name = key + '_' + column\n",
    "            pred_series.name = key + '_' + column\n",
    "\n",
    "            # Add the series to the list\n",
    "            backtest_list.append(backtest_series)\n",
    "            pred_list.append(pred_series)\n",
    "\n",
    "    # lgbm\n",
    "    for key in lgbm_results.keys():\n",
    "\n",
    "        backtest_series = lgbm_results[key]['backtest'].groupby([\"date\"]).sum().pred\n",
    "        pred_series  = lgbm_results[key][\"pred\"].groupby([\"date\"]).sum().pred\n",
    "\n",
    "\n",
    "        # Rename the series to the current key\n",
    "        backtest_series.name = key + \"_lgbm\"\n",
    "        pred_series.name = key + \"_lgbm\"\n",
    "\n",
    "        # Add the series to the list\n",
    "        backtest_list.append(backtest_series)\n",
    "        pred_list.append(pred_series)\n",
    "\n",
    "    # xgb\n",
    "    for key in xgb_results.keys():\n",
    "\n",
    "        backtest_series = xgb_results[key]['backtest'].groupby([\"date\"]).sum().pred\n",
    "        pred_series  = xgb_results[key][\"pred\"].groupby([\"date\"]).sum().pred\n",
    "\n",
    "\n",
    "        # Rename the series to the current key\n",
    "        backtest_series.name = key + \"_xgb\"\n",
    "        pred_series.name = key + \"_xgb\"\n",
    "\n",
    "        # Add the series to the list\n",
    "        backtest_list.append(backtest_series)\n",
    "        pred_list.append(pred_series)\n",
    "\n",
    "    # lstm \n",
    "\n",
    "    for key in lstm_results.keys():\n",
    "\n",
    "        backtest_series = lstm_results[key]['backtest'].groupby([\"date\"]).sum().pred\n",
    "        pred_series  = lstm_results[key][\"pred\"].groupby([\"date\"]).sum().pred\n",
    "\n",
    "\n",
    "        # Rename the series to the current key\n",
    "        backtest_series.name = key + \"_lstm\"\n",
    "        pred_series.name = key + \"_lstm\"\n",
    "\n",
    "        # Add the series to the list\n",
    "        backtest_list.append(backtest_series)\n",
    "        pred_list.append(pred_series)\n",
    "        \n",
    "    # nhits\n",
    "    for key in lstm_results.keys():\n",
    "\n",
    "        backtest_series = nhits_results[key]['backtest'].groupby([\"date\"]).sum().pred\n",
    "        pred_series  = nhits_results[key][\"pred\"].groupby([\"date\"]).sum().pred\n",
    "\n",
    "\n",
    "        # Rename the series to the current key\n",
    "        backtest_series.name = key + \"_nhits\"\n",
    "        pred_series.name = key + \"_nhits\"\n",
    "\n",
    "        # Add the series to the list\n",
    "        backtest_list.append(backtest_series)\n",
    "        pred_list.append(pred_series)\n",
    "\n",
    "        \n",
    "    # Concatenate all series into one dataframe\n",
    "    backtest_df = pd.concat(backtest_list, axis=1)\n",
    "    pred_df = pd.concat(pred_list, axis=1)\n",
    "\n",
    "    # attach actuals \n",
    "    # Access actual values for backtest and prediction\n",
    "    backtest_df[\"actual\"] = lgbm_results[\"L_3_Time_Momentum_Lag\"][\"backtest\"].groupby([\"date\"]).sum().actual\n",
    "    pred_df[\"actual\"] = lgbm_results[\"L_3_Time_Momentum_Lag\"][\"pred\"].groupby([\"date\"]).sum().actual\n",
    "    \n",
    "    # Set index names\n",
    "    backtest_df.index.name = 'date'\n",
    "    pred_df.index.name = 'date'\n",
    "    \n",
    "    return backtest_df, pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8dea3b6-d494-430c-946e-2d6d406918b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ensemble(backtest_df, pred_df, list_of_selected_models):\n",
    "    # Lists to hold 'pred' series\n",
    "    backtest_list = []\n",
    "    pred_list = []\n",
    "\n",
    "    # create list of combinations\n",
    "    model_pairs = list(combinations(list_of_selected_models, 2))\n",
    "\n",
    "    for pair in model_pairs:\n",
    "        # create ensembeles \n",
    "        backtest_ensemble = (backtest_df[pair[0]] + backtest_df[pair[1]]) / 2\n",
    "        pred_ensemble = (pred_df[pair[0]] + pred_df[pair[1]]) / 2\n",
    "\n",
    "        # Rename the series to the current key\n",
    "        backtest_ensemble.name = pair[0] + \"_\" + pair[1]\n",
    "        pred_ensemble.name = pair[0] + \"_\" + pair[1]\n",
    "\n",
    "        # Add the series to the list\n",
    "        backtest_list.append(backtest_ensemble)\n",
    "        pred_list.append(pred_ensemble)\n",
    "\n",
    "    back_ens_df = pd.concat(backtest_list, axis=1)\n",
    "    pred_ens_df = pd.concat(pred_list, axis=1)\n",
    "    \n",
    "    # Set index names\n",
    "    back_ens_df.index.name = 'date'\n",
    "    pred_ens_df.index.name = 'date'\n",
    "\n",
    "    return back_ens_df, pred_ens_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dabb6dca-c34d-44ea-91d6-d7b0aede2127",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensemble_metrics(backtest_df, pred_df):\n",
    "    \n",
    "    # Initialize an empty list to store the results\n",
    "    metrics_data = []\n",
    "\n",
    "    # Iterate over the dataframes and categories\n",
    "\n",
    "    for category_name in backtest_df.columns:\n",
    "        # Access backtest data frame for the current level and category\n",
    "        backtest = backtest_df[category_name]\n",
    "        # Access prediction data frame for the current level and category\n",
    "        pred = pred_df[category_name]\n",
    "\n",
    "        # Calculate RMSE\n",
    "        val_rmse = np.sqrt(mse(backtest_df.actual, backtest))\n",
    "        pred_rmse = np.sqrt(mse(pred_df.actual, pred))\n",
    "\n",
    "        # Calculate MAPE\n",
    "        val_mape = mape(backtest_df.actual, backtest)\n",
    "        pred_mape = mape(pred_df.actual, pred)\n",
    "\n",
    "        # Calculate MAE\n",
    "        val_mae = mae(backtest_df.actual, backtest)\n",
    "        pred_mae = mae(pred_df.actual, pred)\n",
    "\n",
    "        # Append the results to the metrics_data list\n",
    "        metrics_data.append({\n",
    "            'category': category_name,\n",
    "            'val_rmse': val_rmse,\n",
    "            'pred_rmse': pred_rmse,\n",
    "            'val_mape': val_mape,\n",
    "            'pred_mape': pred_mape,\n",
    "            #'val_mae': val_mae,\n",
    "            #'pred_mae': pred_mae\n",
    "        })\n",
    "        \n",
    "        ensemble_metrics = pd.DataFrame(metrics_data)\n",
    "        \n",
    "    return ensemble_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e7dd84-a2c2-4a7a-81c4-88f313f7b2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensemble_stats(backtest_df, pred_df):\n",
    "    # Initialize lists to store the values\n",
    "    column_names = []\n",
    "    means = []\n",
    "    standard_deviations = []\n",
    "\n",
    "    # Calculate mean and standard deviation for each column\n",
    "    for i in backtest_df.columns:\n",
    "        mean = backtest_df[i].mean()\n",
    "        standard_deviation = backtest_df[i].std()\n",
    "\n",
    "        # Append the results to the lists\n",
    "        column_names.append(i)\n",
    "        means.append(mean)\n",
    "        standard_deviations.append(standard_deviation)\n",
    "\n",
    "    # Create new DataFrame\n",
    "    stats_df = pd.DataFrame({\n",
    "        'Column Name': column_names,\n",
    "        'Mean': means,\n",
    "        'Standard Deviation': standard_deviations\n",
    "    })\n",
    "    \n",
    "    return stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e23e2140-f145-44bc-bd8f-b64c318f18b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Functions and get individual metrics (without ensembles)\n",
    "back_df, pred_df = back_pred_df(ts_results, lgbm_results, xgb_results, lstm_results, nhits_results)\n",
    "ind_metrics_df = ensemble_metrics(back_df, pred_df).sort_values(\"val_mape\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d10b4109-e176-4a99-ac8a-30aa3d0c2291",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get nest Models to create ensembles (to limit compexity)\n",
    "list_of_selected_models = list(ind_metrics_df[1:11].category)\n",
    "list_of_selected_models.append(\"L_4_sarimax\")\n",
    "\n",
    "# Create ensemble and save as df\n",
    "back_ens_df, pred_ens_df = create_ensemble(back_df, pred_df, list_of_selected_models)\n",
    "\n",
    "# Backtest and prediction values \n",
    "full_back_df = back_df.merge(back_ens_df,  left_index=True, right_index=True, how=\"left\")\n",
    "full_pred_df = pred_df.merge(pred_ens_df,  left_index=True, right_index=True, how=\"left\")\n",
    "\n",
    "# esemble metrics\n",
    "ensemble_metrics_df = ensemble_metrics(full_back_df, full_pred_df).sort_values(\"pred_rmse\")\n",
    "# test\n",
    "#ensemble_metrics_df.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a4a268-d18c-4e75-a994-efcf4cbee618",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_metrics_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4588597b-6b69-465c-8fbb-7fdd5f6b07bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_results[\"L_4_Time_Momentum_Lag\"][\"backtest\"].groupby(\"date\").sum().actual.plot()\n",
    "lgbm_results[\"L_4_Time_Momentum_Lag\"][\"backtest\"].groupby(\"date\").sum().pred.plot()\n",
    "ts_results[\"L_4\"][\"backtest\"].reset_index().groupby(\"index\").sum().sarimax.plot()\n",
    "#full_back_df.L_4_Time_Momentum_Lag_lgbm_L_4_sarimax.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ef8e55-52cf-400b-8a0b-585ea22dbf2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f31297-b1d9-4e90-96de-541f414bc4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_selected_models.append(\"L_4_sarimax\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e7c5eae-38ac-4b57-8bfd-0dee1f47c268",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(full_back_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fdd3fbb-2191-41d5-98aa-16bbc95e5c30",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## SAVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899b51f5-04d6-4321-bc1c-eef2cdd2d956",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "#with open('../data/modelling_results/ens_back_results.pickle', 'wb') as handle:\n",
    "#    pickle.dump(full_back_df, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "#with open('../data/modelling_results/ens_pred_results.pickle', 'wb') as handle:\n",
    "#    pickle.dump(full_pred_df, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "# save to excel \n",
    "#ensemble_metrics_df.to_excel(\"../data/modelling_results/ensemble_metrics.xlsx\")\n",
    "#ind_metrics_df.to_excel(\"../data/modelling_results/ind_metrics.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de9422e-d03d-4e1f-a055-1be8cbe6c4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(pd.read_pickle(\"../data/modelling_results/ens_back_results.pickle\").columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fefae28-60b5-44a6-9031-79de42b4f3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(pd.read_pickle(\"../data/modelling_results/ens_back_results_v2.pickle\").columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b90cdd4-eaaa-4279-8447-ca68a77adc49",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Significance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed6350a-fd8c-46ac-9d63-82accad00280",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_rel, shapiro\n",
    "from scipy.stats import wilcoxon\n",
    "\n",
    "# Assuming your DataFrame is called 'df' and has columns 'actual', 'backtest', 'prediction'\n",
    "df = pd.DataFrame(metrics_data)\n",
    "\n",
    "test = df[df[\"category\"] == \"L_5_Time_Momentum_Lag\"]\n",
    "\n",
    "stat_backtest, p_backtest = shapiro(df['val_mae'])\n",
    "stat_prediction, p_prediction = shapiro(df['pred_mae'])\n",
    "\n",
    "alpha = 0.05  # Choose your significance level\n",
    "\n",
    "if p_backtest < alpha or p_prediction < alpha:\n",
    "    print(\"At least one of the MAE distributions is not normal. Consider using a non-parametric test.\")\n",
    "else:\n",
    "    # Perform paired t-test\n",
    "    t_stat, p_value = ttest_rel(df['mae_backtest'], df['mae_prediction'])\n",
    "\n",
    "    if p_value < alpha:\n",
    "        print(\"There is a significant difference between the two models (p-value: {:.5f})\".format(p_value))\n",
    "    else:\n",
    "        print(\"There is no significant difference between the two models (p-value: {:.5f})\".format(p_value))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4686a94-c29c-4beb-ba29-b29a4ce78edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "alpha1 = 0.05  # Set a significance level (e.g., 0.05)\n",
    "alpha2 = 0.01  # Set a significance level (e.g., 0.01)\n",
    "\n",
    "significance_results = []\n",
    "\n",
    "for category_name, _ in lgb_params.items():\n",
    "    # Access backtest data frame for the current level and category\n",
    "    backtest_lgb = lgbm_tr[f\"{category_name}\"]['backtest'].groupby(\"date\").sum()\n",
    "    backtest_arima = ts_backtest.ARIMA\n",
    "\n",
    "    # Access prediction data frame for the current level and category\n",
    "    pred_lgb = lgbm_tr[f\"{category_name}\"]['pred'].groupby(\"date\").sum()\n",
    "    pred_arima = ts_forecast.ARIMA\n",
    "\n",
    "    # Perform the Wilcoxon Signed-Rank Test for backtest errors\n",
    "    stat_backtest, p_value_backtest = wilcoxon(backtest_lgb.actual - backtest_lgb.pred, backtest_lgb.actual - backtest_arima)\n",
    "\n",
    "    # Perform the Wilcoxon Signed-Rank Test for prediction errors\n",
    "    stat_pred, p_value_pred = wilcoxon(pred_lgb.actual - pred_lgb.pred, backtest_lgb.actual - pred_arima)\n",
    "\n",
    "    significance_backtest = 0\n",
    "    if p_value_backtest < alpha1:\n",
    "        significance_backtest = 1\n",
    "    if p_value_backtest < alpha2:\n",
    "        significance_backtest = 2\n",
    "\n",
    "    significance_pred = 0\n",
    "    if p_value_pred < alpha1:\n",
    "        significance_pred = 1\n",
    "    if p_value_pred < alpha2:\n",
    "        significance_pred = 2\n",
    "\n",
    "    significance_results.append([category_name, significance_backtest, significance_pred])\n",
    "\n",
    "# Create a DataFrame with the results\n",
    "significance_df = pd.DataFrame(significance_results, columns=['Category', 'Backtest Significance', 'Prediction Significance'])\n",
    "\n",
    "# save to excel \n",
    "#significance_df.to_excel(\"../data/modelling_results/lgbm_significance.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b19b9e1a-6480-4789-97b6-4eb36c6913d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cb470474-eec2-4361-9ce8-c238f55d5b3f",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2992b7fa-f281-4b51-a639-7081adb37ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_pickle(\"../data/processed/L_4_test.pkl\").columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73436e26-b071-4207-84b8-1374d759adce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test drop\n",
    "['tm_y_1',\n",
    " 'tm_wm_cos',\n",
    " 'event_Thanksgiving',\n",
    " 'holiday_Zweiter_Weihnachtstag',\n",
    " 'holiday_Ostermontag',\n",
    " 'holiday_Neujahr',\n",
    " 'holiday_Reformationstag',\n",
    " 'holiday_Karfreitag',\n",
    " 'event_Valentines_Day',\n",
    " 'holiday_Pfingstmontag',\n",
    " 'holiday_Erster_Mai',\n",
    " 'holiday_Erster_Weihnachtstag',\n",
    " 'holiday_Tag_der_Deutschen_Einheit',\n",
    " 'holiday_Christi_Himmelfahrt',\n",
    " 'tm_y_2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b8eaf8-d90c-426f-b9ff-c841aee2a7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "nr_freatures = 10\n",
    "# Permutation Iportance of lgbm moddels\n",
    "fig, axes = plt.subplots(6, 2, figsize=(12, 20))  # figsize in inches, changed to fit A4 dimensions\n",
    "axes = axes.ravel()  # Flatten the axes array for easier indexing\n",
    "\n",
    "# Iterate through the feature_importance dictionary items and get the level and value\n",
    "for idx, (level, value) in enumerate(lgbm_importance.items()):\n",
    "    df = value[\"df\"].sort_index()\n",
    "    box_array = value[\"box_array\"]\n",
    "    columns = df.feature_names\n",
    "    sns.boxplot(x=\"importance\", y=\"feature_names\", data=pd.DataFrame(box_array, columns=columns)\\\n",
    "                .melt(var_name='feature_names', value_name='importance').sort_values(\"importance\", ascending=False),#.head(nr_freatures), \n",
    "                ax=axes[idx], \n",
    "                order=df.sort_values(\"importances_mean\", ascending=False).head(nr_freatures).feature_names,\n",
    "                color=\"grey\")\n",
    "    axes[idx].set_title(f'{level}', fontsize=10)  # adjust fontsize\n",
    "    axes[idx].set_xlabel('Importance', fontsize=8)  # adjust fontsize\n",
    "    axes[idx].set_ylabel('Features', fontsize=8)  # adjust fontsize\n",
    "    plt.yticks(rotation=0)\n",
    "\n",
    "# Remove the unused subplot in case you have an odd number of plots\n",
    "if len(lgbm_importance) % 2 == 1:\n",
    "    fig.delaxes(axes[-1])\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the figure as a PNG file\n",
    "##plt.savefig('../data/figures/all_feature_importance_per_cat_lgbm.png', dpi=300, bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "314f2a3f-ced5-4f49-bb04-727e6ab6226f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#I made these calc:\n",
    "df['tm_dy'] = df.date.dt.dayofyear.astype(np.int8)  # Day of year +\n",
    "df['tm_dm'] = df.date.dt.day.astype(np.int8)  # Day of month +\n",
    "df['tm_wy'] = df.date.dt.isocalendar().week.astype(np.int8)  # week of year +\n",
    "df['tm_my'] = df.date.dt.month.astype(np.int8)  # month of year +\n",
    "df['tm_y'] = df.date.dt.year  # year\n",
    "df['tm_y'] = (df['tm_y'] - df['tm_y'].min()).astype(np.int8)  # year - min year = number of year\n",
    "df['tm_wm'] = df['tm_dm'].apply(lambda x: math.ceil(x / 7)).astype(np.int8)  # number of week in month\n",
    "df['tm_dw'] = df.date.dt.dayofweek.astype(np.int8)  # number of day in week # +\n",
    "df['tm_w_end'] = (df['tm_dw'] >= 5).astype(np.int8)  # indicate Weekend\n",
    "\n",
    "# Momentum Features: Rolling averages and standard dev 9 & 14 days\n",
    "product_sales['q_roll_mean_9d'] = product_sales.groupby([i])['quantity'].shift(9).rolling(9, min_periods=1)\\\n",
    "    .mean().reset_index().quantity.fillna(0)\n",
    "product_sales['q_roll_std_9d'] = product_sales.groupby([i])['quantity'].shift(9).rolling(9, min_periods=1)\\\n",
    "    .std().reset_index().quantity.fillna(0)\n",
    "product_sales['q_roll_mean_14d'] = product_sales.groupby([i])['quantity'].shift(9).rolling(14, min_periods=1)\\\n",
    "    .mean().reset_index().quantity.fillna(0)\n",
    "product_sales['q_roll_std_14d'] = product_sales.groupby([i])['quantity'].shift(9).rolling(14, min_periods=1)\\\n",
    "    .std().reset_index().quantity.fillna(0)\n",
    "\n",
    "# Lag Features 9 days, 14 day, 28 days and 365 days\n",
    "product_sales['q_lag_9d'] = product_sales.groupby([i])['quantity'].shift(periods=9).fillna(0)\n",
    "product_sales['q_lag_14d'] = product_sales.groupby([i])['quantity'].shift(periods=14).fillna(0)\n",
    "product_sales['q_lag_28d'] = product_sales.groupby([i])['quantity'].shift(periods=28).fillna(0)\n",
    "product_sales['q_lag_365d'] = product_sales.groupby([i])['quantity'].shift(periods=365).fillna(0)\n",
    "\n",
    "# average of 9, 14 and 28 days\n",
    "product_sales[\"q_mean_lag_9_14_28\"] = (product_sales['q_lag_9d'] + product_sales['q_lag_14d']\n",
    "                                       + product_sales['q_lag_28d'])/3\n",
    "\n",
    "# help me rename these featues to consise intuitive names\n",
    "df.feature_names.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14897981-264d-4579-8e59-4f45960229e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "value = lgbm_importance[\"L_6_Time_Momentum_Lag_Weather_Holiday\"]\n",
    "\n",
    "df = value[\"df\"].sort_index()\n",
    "\n",
    "# Assuming df is your DataFrame\n",
    "# Rename the values in column feature_names not columns\n",
    "rename_dict = {\n",
    "    'tm_dm_cos': 'day_month_cos',\n",
    "    'tm_dm_sin': 'day_month_sin',\n",
    "    'tm_y_2': 'year_2',\n",
    "    'tm_dy_sin': 'day_year_sin',\n",
    "    'tm_w_end': 'is_weekend',\n",
    "    'tm_dy_cos': 'day_year_cos',\n",
    "    'tm_y_1': 'year_1',\n",
    "    'tm_wy_sin': 'week_year_sin',\n",
    "    'tm_y_0': 'year_0',\n",
    "    'tm_wm_sin': 'week_month_sin',\n",
    "    'tm_my_cos': 'month_year_cos',\n",
    "    'tm_my_sin': 'month_year_sin',\n",
    "    'tm_dw_sin': 'day_week_sin',\n",
    "    'tm_dw_cos': 'day_week_cos',\n",
    "    'tm_wm_cos': 'week_month_cos',\n",
    "    'tm_wy_cos': 'week_year_cos',\n",
    "    'q_roll_std_9d': 'quantity_rolling_std_9d',\n",
    "    'q_lag_14d': 'quantity_lag_14d',\n",
    "    'q_lag_28d': 'quantity_lag_28d',\n",
    "    'q_mean_lag_9_14_28': 'quantity_mean_lag_9_14_28',\n",
    "    'q_lag_9d': 'quantity_lag_9d',\n",
    "    'q_roll_std_14d': 'quantity_rolling_std_14d',\n",
    "    'q_lag_365d': 'quantity_lag_365d',\n",
    "    'q_roll_mean_9d': 'quantity_rolling_mean_9d',\n",
    "    'q_roll_mean_14d': 'quantity_rolling_mean_14d',\n",
    "}\n",
    "\n",
    "# Your DataFrame df now has renamed columns\n",
    "df['feature_names'] = df['feature_names'].replace(rename_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b38d30f0-28b6-45a5-91d8-5a6618594445",
   "metadata": {},
   "outputs": [],
   "source": [
    "box_array = value[\"box_array\"]\n",
    "columns = df.feature_names\n",
    "\n",
    "fig, axes = plt.subplots(figsize=(15, 8))  # figsize in inches, changed to fit A4 dimensions\n",
    "\n",
    "sns.boxplot(x=\"importance\", y=\"feature_names\",\n",
    "            data=pd.DataFrame(box_array, columns=columns).melt(var_name='feature_names', \n",
    "                                                               value_name='importance').sort_values(\"importance\", \n",
    "                                                                                                    ascending=False),\n",
    "            ax=axes,\n",
    "            order=df.sort_values(\"importances_mean\", ascending=False).head(30).feature_names,\n",
    "            color=\"grey\")\n",
    "\n",
    "#axes.set_title('Feature Importances: L6_Weather_Holiday_lgbm', fontsize=10)  # adjust fontsize\n",
    "axes.set_xlabel('Importance', fontsize=10)  # adjust fontsize\n",
    "axes.set_ylabel('Features', fontsize=10)  # adjust fontsize\n",
    "plt.yticks(rotation=0)\n",
    "\n",
    "plt.savefig('../data/figures/feature_importance_L6_all_features_lgbm.png', dpi=300, bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "651010a7-2c4d-4344-b746-e383d4b7c0ae",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Visualisation\n",
    "\n",
    "Best Performing from every level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f08fd4dc-99ae-49e4-8686-f08085dea358",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = back_df.append(pred_df)\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5c14b4-5b33-4440-a035-247614f778fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_ts_models = pd.Series(ts_error.sort_values(\"pred_rmse\")[0:1].index.unique())\n",
    "best_lgbm_models = pd.Series(lgbm_error.sort_values(\"pred_rmse\")[0:1].category.unique())\n",
    "#best_xgb_models = pd.Series(xgb_error[0:1].category.unique())\n",
    "#best_lstm_models = pd.Series(lstm_error[0:1].index.unique())\n",
    "best_nhits_models = pd.Series(nhits_error.sort_values(\"pred_rmse\")[0:1].index.unique())\n",
    "#best_ens_models = pd.Series(ensemble_metrics_df[2:3].category.unique())  # best 2!\n",
    "\n",
    "# add \"_lgbm\" and \"_xgb\" to best_lgbm_models and best_xgb_models\n",
    "best_lgbm_models = best_lgbm_models.map(lambda x: f'{x}_lgbm')\n",
    "#best_xgb_models = best_xgb_models.map(lambda x: f'{x}_xgb')\n",
    "\n",
    "list_of_best_models = pd.concat([best_ts_models, best_lgbm_models, best_nhits_models])\n",
    "\n",
    "# Set the style for the plot\n",
    "sns.set(style=\"whitegrid\", font_scale=1)\n",
    "\n",
    "# Create the time series plot\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "# Plot each model\n",
    "for model in list_of_best_models:\n",
    "    plt.plot(merged_df.index, merged_df[model], label=model, linestyle=\"--\", alpha=0.9)\n",
    "\n",
    "# The rest of your code...\n",
    "# Plot the Actuals with a thicker, solid line and a distinct color\n",
    "plt.plot(merged_df.index, merged_df[\"actual\"], label=\"Actuals\", color=\"black\", linewidth=1.5)\n",
    "\n",
    "# Get the number of y-ticks\n",
    "n = len(plt.gca().get_yticks())\n",
    "\n",
    "# Set new y-tick labels\n",
    "plt.yticks(np.linspace(min(pred_df[\"actual\"]), max(pred_df[\"actual\"]), n), range(1, n+1))\n",
    "\n",
    "# Customize the plot\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Scaled Daily Orders\")\n",
    "plt.legend(loc=\"best\", fontsize=10)\n",
    "# Hide y-axis values\n",
    "#plt.yticks([])\n",
    "\n",
    "plt.tight_layout()\n",
    "# save\n",
    "#plt.savefig('../data/figures/forecast_comparison_best_category.png', dpi=300, bbox_inches='tight')\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a7153b-a67e-413d-8713-e8623f2b9f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the style for the plot\n",
    "sns.set(style=\"whitegrid\", font_scale=1)\n",
    "\n",
    "# Create the time series plot\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "# Plot each model\n",
    "for model in list_of_best_models:\n",
    "    \n",
    "    # add if statement. If model in pred_ens_df plot else plot with pred_df\n",
    "    if model in pred_ens_df.columns:\n",
    "        plt.plot(back_ens_df.index, back_ens_df[model], label=model, linestyle=\"--\", alpha=0.9)\n",
    "        \n",
    "    else:\n",
    "        plt.plot(back_df.index, back_df[model], label=model, linestyle=\"--\", alpha=0.9)\n",
    "\n",
    "# The rest of your code...\n",
    "# Plot the Actuals with a thicker, solid line and a distinct color\n",
    "plt.plot(back_df.index, back_df[\"actual\"], label=\"Actuals\", color=\"black\", linewidth=1.5)\n",
    "\n",
    "# Get the number of y-ticks\n",
    "n = len(plt.gca().get_yticks())\n",
    "\n",
    "# Set new y-tick labels\n",
    "plt.yticks(np.linspace(min(pred_df[\"actual\"]), max(pred_df[\"actual\"]), n), range(1, n+1))\n",
    "\n",
    "# Customize the plot\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Scaled Daily Orders\")\n",
    "plt.legend(loc=\"best\", fontsize=10)\n",
    "\n",
    "# Hide y-axis values\n",
    "#plt.yticks([])\n",
    "\n",
    "plt.tight_layout()\n",
    "# save\n",
    "plt.savefig('../data/figures/backtest_comparison_best_category.png', dpi=300, bbox_inches='tight')\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a32691f-ff90-4724-944a-69fcd18b5a7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f85aa593-90fa-43b8-bd98-958975f8ef8a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:miniconda3-snowflakes]",
   "language": "python",
   "name": "conda-env-miniconda3-snowflakes-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
